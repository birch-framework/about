<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KafkaAdminUtils.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">birch-kafka-utils</a> &gt; <a href="index.source.html" class="el_package">org.birchframework.framework.kafka</a> &gt; <span class="el_source">KafkaAdminUtils.java</span></div><h1>KafkaAdminUtils.java</h1><pre class="source lang-java linenums">/*===============================================================
 = Copyright (c) 2021 Birch Framework
 = This program is free software: you can redistribute it and/or modify
 = it under the terms of the GNU General Public License as published by
 = the Free Software Foundation, either version 3 of the License, or
 = any later version.
 = This program is distributed in the hope that it will be useful,
 = but WITHOUT ANY WARRANTY; without even the implied warranty of
 = MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 = GNU General Public License for more details.
 = You should have received a copy of the GNU General Public License
 = along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
 ==============================================================*/
package org.birchframework.framework.kafka;

import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.concurrent.ExecutionException;
import java.util.stream.Collectors;
import javax.annotation.PreDestroy;
import com.google.common.base.Throwables;
import lombok.Getter;
import lombok.extern.slf4j.Slf4j;
import org.apache.commons.lang3.ObjectUtils;
import org.apache.commons.lang3.StringUtils;
import org.apache.commons.lang3.time.StopWatch;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.ConsumerGroupListing;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.birchframework.configuration.BirchProperties;
import org.springframework.boot.context.properties.PropertyMapper;

import static org.apache.kafka.clients.CommonClientConfigs.SECURITY_PROTOCOL_CONFIG;
import static org.apache.kafka.clients.admin.AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG;
import static org.apache.kafka.clients.consumer.ConsumerConfig.*;
import static org.apache.kafka.clients.producer.ProducerConfig.*;
import static org.apache.kafka.common.config.SaslConfigs.*;
import static org.apache.kafka.common.config.SslConfigs.SSL_PROTOCOL_CONFIG;

/**
 * Kafka administration utilities.
 * @author Keivan Khalichi
 */
<span class="fc" id="L49">@Slf4j</span>
@SuppressWarnings(&quot;PMD.TooManyStaticImports&quot;)
public class KafkaAdminUtils {

<span class="fc" id="L53">   private static final PropertyMapper mapper = PropertyMapper.get();</span>

<span class="fc" id="L55">   @Getter</span>
   private final Map&lt;String, Object&gt;           kafkaConfigs;
   private final KafkaConsumer&lt;Object, Object&gt; kafkaConsumer;
   private final AdminClient                   adminClient;

<span class="fc" id="L60">   KafkaAdminUtils(final BirchProperties theProperties) {</span>
<span class="fc" id="L61">      final var aKafkaProperties = theProperties.getKafka().getAdmin();</span>

<span class="fc" id="L63">      final var aKafkaConfigs = new HashMap&lt;String, Object&gt;();</span>
<span class="fc" id="L64">      aKafkaConfigs.put(BOOTSTRAP_SERVERS_CONFIG, String.join(&quot;,&quot;, aKafkaProperties.getBootstrapServers()));</span>
<span class="pc" id="L65">      mapper.from(aKafkaProperties.getSslProtocol()).when(StringUtils::isNotBlank).to(v -&gt; aKafkaConfigs.put(SSL_PROTOCOL_CONFIG, v));</span>
<span class="pc" id="L66">      mapper.from(aKafkaProperties.getSecurityProtocol()).when(StringUtils::isNotBlank).to(v -&gt; aKafkaConfigs.put(SECURITY_PROTOCOL_CONFIG, v));</span>
<span class="fc" id="L67">      mapper.from(aKafkaProperties.getKeySerializer()).whenNonNull().to(v -&gt; aKafkaConfigs.put(KEY_SERIALIZER_CLASS_CONFIG, v));</span>
<span class="fc" id="L68">      mapper.from(aKafkaProperties.getValueSerializer()).whenNonNull().to(v -&gt; aKafkaConfigs.put(VALUE_SERIALIZER_CLASS_CONFIG, v));</span>
<span class="fc" id="L69">      aKafkaConfigs.put(KEY_DESERIALIZER_CLASS_CONFIG, ObjectUtils.defaultIfNull(aKafkaProperties.getKeyDeserializer(), StringDeserializer.class));</span>
<span class="fc" id="L70">      aKafkaConfigs.put(VALUE_DESERIALIZER_CLASS_CONFIG, ObjectUtils.defaultIfNull(aKafkaProperties.getValueDeserializer(), StringDeserializer.class));</span>
<span class="pc" id="L71">      mapper.from(aKafkaProperties.getSasl().getJaasConfig()).whenNonNull().to(v -&gt; aKafkaConfigs.put(SASL_JAAS_CONFIG, v));</span>
<span class="pc" id="L72">      mapper.from(aKafkaProperties.getSasl().getMechanism()).whenNonNull().to(v -&gt; aKafkaConfigs.put(SASL_MECHANISM, v));</span>

<span class="fc" id="L74">      this.kafkaConfigs  = Collections.unmodifiableMap(aKafkaConfigs);</span>
<span class="fc" id="L75">      this.kafkaConsumer = new KafkaConsumer&lt;&gt;(aKafkaConfigs);</span>
<span class="fc" id="L76">      this.adminClient   = AdminClient.create(aKafkaConfigs);</span>
<span class="fc" id="L77">   }</span>

   @PreDestroy
   void preDestroy() {
<span class="nc" id="L81">      this.kafkaConsumer.close();</span>
<span class="nc" id="L82">   }</span>

   /**
    * Calculates consumer lag for all active consumers.
    * &lt;b&gt;NOTE:&lt;/b&gt; if a topic has no consumers, then it will not appear in the return mapping.
    * @return map of topic name to total consumer lag
    */
   @SuppressWarnings({&quot;AutoBoxing&quot;, &quot;AutoUnboxing&quot;})
   public Map&lt;String, Long&gt; topicLags() {
<span class="pc bpc" id="L91" title="1 of 2 branches missed.">      final StopWatch aStopWatch = log.isDebugEnabled() ? StopWatch.createStarted() : null;</span>

      try {
<span class="fc" id="L94">         final var aConsumerGroupIDs = this.adminClient.listConsumerGroups()</span>
<span class="fc" id="L95">                                                       .valid()</span>
<span class="fc" id="L96">                                                       .thenApply(result -&gt; result.stream().map(ConsumerGroupListing::groupId).collect(Collectors.toList()))</span>
<span class="fc" id="L97">                                                       .get();</span>
<span class="fc" id="L98">         final Map&lt;TopicPartition, OffsetAndMetadata&gt; aTopicAndOffsetMap = new HashMap&lt;&gt;();</span>
<span class="fc" id="L99">         aConsumerGroupIDs.stream()</span>
<span class="fc" id="L100">                          .map(id -&gt; this.adminClient.listConsumerGroupOffsets(id).partitionsToOffsetAndMetadata())</span>
<span class="fc" id="L101">                          .forEach(future -&gt; {</span>
                             try {
<span class="fc" id="L103">                                aTopicAndOffsetMap.putAll(future.get());</span>
                             }
<span class="nc" id="L105">                             catch (InterruptedException e) {</span>
<span class="nc" id="L106">                                log.warn(&quot;Unable to retrieve topic offsets for a consumer group; error message: {}&quot;, Throwables.getRootCause(e).getMessage());</span>
<span class="nc" id="L107">                                Thread.currentThread().interrupt();</span>
<span class="nc" id="L108">                                throw new RuntimeException(e);</span>
                             }
<span class="nc" id="L110">                             catch (ExecutionException e) {</span>
<span class="nc" id="L111">                                log.warn(&quot;Unable to retrieve topic offsets for a consumer group; error message: {}&quot;, Throwables.getRootCause(e).getMessage());</span>
<span class="fc" id="L112">                             }</span>
<span class="fc" id="L113">                          });</span>
         final Map&lt;TopicPartition, Long&gt; aTopicEndOffsets;
<span class="fc" id="L115">         synchronized(this.kafkaConsumer) {</span>
<span class="fc" id="L116">            aTopicEndOffsets = this.kafkaConsumer.endOffsets(aTopicAndOffsetMap.keySet());</span>
<span class="fc" id="L117">         }</span>
<span class="fc" id="L118">         final var aTopicPartitionLagMap = aTopicAndOffsetMap.entrySet()</span>
<span class="fc" id="L119">                                                             .stream()</span>
<span class="fc" id="L120">                                                             .collect(Collectors.toMap(</span>
                                                                Entry::getKey,
                                                                entry -&gt; {
<span class="fc" id="L123">                                                                   final var anEndOffset = aTopicEndOffsets.get(entry.getKey());</span>
<span class="fc" id="L124">                                                                   final var aLag = anEndOffset - entry.getValue().offset();</span>
<span class="pc bpc" id="L125" title="1 of 2 branches missed.">                                                                   return aLag &lt; 0 ? 0 : aLag;</span>
                                                                }
                                                             ));
<span class="fc" id="L128">         final var aTopicLags = new HashMap&lt;String, Long&gt;();</span>
<span class="pc bpc" id="L129" title="1 of 2 branches missed.">         aTopicPartitionLagMap.forEach((key, value) -&gt; aTopicLags.compute(key.topic(), (k, v) -&gt; v == null ? value : v + value));</span>
<span class="fc" id="L130">         return aTopicLags;</span>
      }
<span class="nc" id="L132">      catch (InterruptedException e) {</span>
<span class="nc" id="L133">         log.warn(&quot;Unable to retrieve consumer groups; error message: {}&quot;, Throwables.getRootCause(e).getMessage());</span>
<span class="nc" id="L134">         Thread.currentThread().interrupt();</span>
<span class="nc" id="L135">         throw new RuntimeException(e);</span>
      }
<span class="nc" id="L137">      catch (ExecutionException e) {</span>
<span class="nc" id="L138">         log.warn(&quot;Unable to retrieve consumer groups; error message: {}&quot;, Throwables.getRootCause(e).getMessage());</span>
<span class="nc" id="L139">         return Collections.emptyMap();</span>
      }
      finally {
<span class="pc bpc" id="L142" title="1 of 2 branches missed.">         if (aStopWatch != null) {</span>
<span class="nc" id="L143">            log.debug(&quot;Completed lag calculation in {} milliseconds&quot;, aStopWatch.getTime());</span>
         }
      }
   }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.7.202105040129</span></div></body></html>